---
title: '给原型加上 AI 能力 - 接入文本与图像 API'
description: '在已有 Web 原型中接入真实的 AI 能力：理解 API 的核心概念，学会找到 API Key 和官方示例；实战集成 DeepSeek 文本模型与多种图像生成服务（SiliconFlow Qwen-Image、Recraft、Seedream），并掌握常用的模型选型方法。'
---

<script setup>
const duration = '约 <strong>1 天</strong>'
</script>

# 初级四：给原型加上 AI 能力

## 本章导读

<ChapterIntroduction :duration="duration" :tags="['API', '文本模型', '文生图', '原型集成']" coreOutput="原型接入 1 个文本模型 + 1 个图像模型（可选）" expectedOutput="可调用真实 API 的 AI 原型">

在上一节中，你已经做出了一个「能跑起来」的产品原型；但只靠静态页面和前端逻辑，它离“能真正帮你提高效率”还差一步：把 AI 能力接进来。

本章会用非常务实的视角讲清楚一件事：**接入任何 AI API，本质上都是“拿到 API Key + 读懂官方示例 + 让 AI 帮你落到代码里”**。你会以 DeepSeek 作为文本模型示例，并从多个图像生成服务中挑一个集成到自己的原型里。

</ChapterIntroduction>

::: warning 🔐 安全与费用提醒
- **API Key 相当于密码**：它能代表“你本人”去调用接口，并且会产生费用。拿到你 Key 的人，不需要再问你确认，也能直接调用。
  - 不要发群、不要截图公开、不要贴到评论区/论坛。
  - 不要写进代码并提交到 Git（尤其是公开仓库）；一旦提交，哪怕你后来删掉，历史记录里也可能还在。
  - 如果你怀疑 Key 泄露了：立刻去平台把 Key 删除/禁用，然后重新生成一个新的。
- **原型阶段可以先跑通，但不要把 Key 放在前端公开代码里**：如果你的网页里直接写了 Key（哪怕你觉得“别人看不到”），只要页面能打开，别人就有机会从浏览器里把 Key 找出来。
  - 原型阶段：你可以先让功能跑通，理解流程即可。
  - 要上线/交付：务必用后端来保存 Key，并由后端去调用 API（初中级开发中会详细展开）。
- **费用是按用量算的**：调用一次就可能消耗一点额度；图片/视频通常比文字更贵。
  - 建议先用免费额度或小额充值完成验证。
  - 测试时尽量用短输入、小图片、少次数；确认没问题再逐步加量。
:::

<div style="margin: 50px 0;">
  <ClientOnly>
    <StepBar :active="0" :items="[
      { title: 'API 基础', description: '可跳过，但很有用' },
      { title: '接入文字', description: '5 分钟跑通一次' },
      { title: '接入图片', description: '5 分钟跑通一次' },
      { title: '实战接入', description: '接进上节原型' },
      { title: '模型选型', description: '看榜单做选择' }
    ]" />
  </ClientOnly>
</div>

## 1. API 基础

如果你已经跑通了“生成文字”和“生成图片”，这一节可以先跳过；等你遇到报错、或者想更稳地改代码时，再回来看会更有用。

API 可以简单理解为：**你按对方要求的格式“发一个问题”，对方就按同样的格式“回一个结果”**。

- **你发出去的内容**：通常包括“密钥（API Key）”和“你要生成什么”
- **对方回给你的内容**：成功就给结果；失败会告诉你原因（比如“密钥不对”“余额不足”“参数写错”）

在原型阶段，你只要记住一句话就够了：

> **拿到 API Key + 找到官方示例 + 让 AI IDE 帮你接到按钮上。**

如果你想看更详细的 0 基础解释，可以看附录：[《API 入门（0 基础版）》](/zh-cn/appendix/api-intro)。

## 2. 接入文本 API（生成文字）

在 `1.2 动手做出原型` 里，你已经做出了一个可交互的原型。接下来我们要做的，是把原型里“看起来像 AI 的功能”变成真正可用的能力：**当用户点击按钮时，原型会向外部的 AI 服务发出请求，并把返回的文字展示出来。**

这一节我们先用一个例子“快速跑通一次”，再把整条接入链条讲清楚。你照着做，0 基础也能完成。

### 2.1 5 分钟接入文字 API：以 DeepSeek 为例

先说明：你现在**不需要写复杂代码，也不需要懂原理**。这 5 分钟要做的事很单纯：

> **把 DeepSeek 的“密钥 + 官方示例”复制到 AI IDE 里，让 AI IDE 帮你把上一节原型的“生成文案”按钮改成真实调用，然后你再点按钮测试。**

你可以把它当成 4 步小任务（按顺序做）：

1. **拿到密钥（API Key）**：去 DeepSeek 平台创建一个 API Key（它相当于“通行证”）。
2. **找到官方示例**：在 DeepSeek 文档里找到“生成文字”的示例（通常可以直接复制）。
3. **复制粘贴到 AI IDE**：把 **API Key + 官方示例** 粘贴进 AI IDE，并告诉它：我要改的是上一节原型里的“生成标题/生成卖点/一键改写”按钮。
4. **回到页面点一下测试**：打开原型，输入一点内容，点击按钮，能看到生成结果就算跑通。

为了让你“更好对齐到上一节的项目”，你可以边打开原型边做这一小节：

> 上一节课项目：[1.2 动手做出原型（电商素材工作台）](/zh-cn/stage-1/1.2-building-prototype/)
>
> 你只需要找到里面的“生成标题/生成卖点/一键改写”这类按钮，把它从“假数据”升级成“真实调用”。

你在素材工作台里，通常会看到这样的流程：

- 输入商品信息（商品名、卖点、目标人群、风格）
- 点击“生成标题/生成卖点”
- 页面出现一段可复制的文字结果

建议你对 AI IDE 这样说（把方括号里的内容换成你项目实际页面名称/按钮文字）：

```text
我有一个上一节做的电商素材工作台原型。

现在我需要把 [生成标题/生成卖点文案/一键改写] 这个按钮接入真实的文本 API：
1) 点击按钮时，读取页面上的输入（商品名/卖点/风格等），拼成一段提示词；
2) 调用 DeepSeek（或你看到我提供的文本 API）的接口拿到生成结果；
3) 把结果显示回页面（替换掉原来的 mock 文本），并加上“加载中/失败提示”； 
4) 告诉我改了哪些文件，以及怎么验证。
```

<!-- TODO: 插入截图：DeepSeek 平台创建 API Key 的页面 -->
<!-- TODO: 插入截图：DeepSeek 文档示例（可复制的那段） -->
<!-- TODO: 插入截图：AI IDE 对话（说明“我要接入上一节的哪个按钮/页面”） -->
<!-- TODO: 插入截图：原型接入成功（点击按钮后出现生成文案） -->
<!-- TODO: 插入截图：素材工作台页面（文案输入区 + “生成标题/生成卖点”按钮） -->
<!-- TODO: 插入截图：接入成功后的页面（展示生成文案结果） -->

### 2.2 文本 API 的接入链条（0 基础版）

把“文字 AI”接进原型，通常就 6 步：

1. **确定入口**：用户在哪里点一下，就应该开始“生成文字”？（例如“生成标题/生成卖点/一键改写”按钮）
2. **收集输入**：用户在页面上填了什么？（商品名、卖点、风格、字数、语气……）
3. **拼出请求内容**：把这些输入拼成一段清楚的话（也就是“提示词”），作为你发给 AI 的内容
4. **发出请求**：把“密钥 + 官方示例”接到代码里，让它真的去请求 AI
5. **把结果显示出来**：把返回的文字写回页面（例如显示在文本框/卡片里）
6. **加上“加载中/报错提示”**：请求需要时间，失败也很正常，给用户一个清晰反馈

你会发现：这条链路里，最难的不是“写代码”，而是第 1～3 步的“把需求变成输入”。这些步骤越清楚，后面的代码就越顺。

<!-- TODO: 插入截图：原型中“生成文案/改写/总结”的入口（来自上一节的原型页面） -->

### 2.3 接入 DeepSeek 文本API

这一小节更“细一点”，把你在 AI IDE 里需要说清楚的话写出来。你照着做就行。

**目标**：从 DeepSeek 拿到密钥 → 从文档复制示例 → 粘贴到 AI IDE → AI IDE 改代码 → 我们回到页面再次测试。

你可以按下面的顺序来：

1. **准备两样东西**
   - **DeepSeek API Key**（在平台创建）
   - **DeepSeek 文档里的“生成文字示例”**（复制即可）
2. **告诉 AI IDE：要改哪个“入口”**
   - 入口就是你原型里那个按钮/页面（例如“生成标题/生成卖点/一键改写”）
   - 你可以补一句：原来是“写死/假数据”，现在要换成真实调用
3. **把“密钥 + 示例 + 入口说明”粘贴给 AI IDE**
   - 让它直接改项目，并要求它告诉你：改了哪些文件、怎么验证
4. **你自己回到页面再次测试**
   - 输入一条商品信息 → 点生成 → 看是否出现“真实生成”的文字
   - 如果失败：把报错提示原样复制回 AI IDE，让它继续修复

### 什么是 DeepSeek

> 提示：文档里可能会出现 “LLM” 这个词。你可以先把它理解为“能生成文字的 AI 模型”，不影响你把 API 接进原型。

![](images/image16.png)

> 📚 信息引用自 [DeepSeek Wiki](https://en.wikipedia.org/wiki/DeepSeek)
>
> **杭州深度求索人工智能基础技术研究有限公司**（**Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd.**），以 **DeepSeek** 为商号，是一家开发大语言模型（LLMs）的中国人工智能（AI）公司。DeepSeek 总部位于浙江杭州，由中国对冲基金幻方量化（High-Flyer）拥有并资助。DeepSeek 由幻方量化的联合创始人梁文锋于 2023 年 7 月创立，他也同时担任这两家公司的 CEO。该公司于 2025 年 1 月推出了同名聊天机器人及其 DeepSeek-R1 模型。
>
> 让我们看看 DeepSeek 在 GPQA 基准排名中与其他顶级模型的表现对比。值得注意的是，DeepSeek 是一个开源（每个人都可以从互联网下载模型）模型，而其他常见模型如 Grok、Google Gemini 和 ChatGPT 都是闭源的。正如我们所见，DeepSeek 已经很大程度上接近了第一梯队的模型。
>
> ![](images/image17.png)
>
> GPQA 是“研究生级 Google-Proof 问答基准”的缩写，这是一个用于科学问答任务的研究生级基准。以下是详细介绍。
>
> GPQA 包含 448 个多项选择题，涵盖生物学、物理学和化学的子领域，如量子力学、有机化学、分子生物学等。这些问题由 61 位持有博士学位或正在攻读博士学位的专家编写，并经过了严格的验证过程。

### 如何获取 DeepSeek API

我们将尝试根据我们已有的信息，让 AI IDE 直接将 DeepSeek API 集成到项目中。

首先，我们需要在 DeepSeek 开放平台注册一个账户。

注册入口：<https://platform.deepseek.com/sign_up>

然后，你会看到像这样的网页界面：

![](images/image18.png)

要使用 API，我们需要先充值一点调用额度。10 元人民币通常足够你完成一轮接入与测试。

![](images/image19.png)

点击 “API KEYS”，并在屏幕下方找到 “create new API key”。你最终会得到一个类似 `sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` 的 API Key。

![](images/image20.png)

一旦你获得了密钥，你就拥有了调用模型的权限。

此时，你可以直接阅读 [API 文档](https://api-docs.deepseek.com/)，它通常提供 curl 或 Python 等调用示例。

![](images/image21.png)

找到示例后，你可以将文档中与「鉴权」和「请求结构」相关的内容复制到 AI IDE，并要求它把 DeepSeek 接入你的项目（例如把“文案生成”“智能改写”“总结”等功能，替换成真实 API 调用）。

你可以直接把下面这段话（按你的项目实际情况改一下）发给 AI IDE，减少沟通成本：

```text
我在上一章已经做了一个可运行的 Web 原型。现在我需要把“文案生成/改写/总结”等功能接入真实的文本 API（生成文字）。

请你根据我提供的 DeepSeek API Key 和官方文档示例：
1) 找到项目中触发文案生成的入口（按钮/表单/页面），把原来的 mock 逻辑替换为真实 API 调用；
2) 把 API Key 放到安全的位置（先不要硬编码到前端源码里；如果不得不临时放，也要提醒我风险）；
3) 告诉我你改动了哪些文件，以及如何验证（例如在页面上输入什么，点哪个按钮，能看到什么返回）。
```

<!-- TODO: 插入截图：AI IDE 对话中粘贴 API Key + 文档示例 + 上面这段说明 -->

![](images/image22.png)

![](images/image23.png)

自动集成通常可以在很短时间内完成。完成后，你可以让 AI IDE 明确回答两件事：

- **它把“调用 AI”的代码放在了哪里**
- **现在请求的是不是 DeepSeek（看“请求地址”和“模型名称”即可）**

![](images/image24.png)

或者，你也可以要求 AI IDE 帮你定位项目中“调用文字生成”的部分。

为了独立确认是否真的在调用 DeepSeek，你可以直接让 AI IDE 帮你定位调用点，例如：

`告诉我项目中所有需要调用文字生成的代码位置，我需要检查是否是 DeepSeek。`

它会返回对应代码位置与请求细节，便于你人工检查（尤其是：请求地址、是否带了密钥、以及模型名称）。

![](images/image25.png)

接下来，我们将简要介绍三种常见的“生成图片”的服务。你可以根据自己的预算、可访问性和效果偏好，选择其中一种集成到 AI IDE 中即可。

## 3. 接入图片 API（生成图片）：从“提示词”到“图片展示”

如果说大语言模型专注于理解、推理和分析我们不知道的所有事物；那么图像和视频模型则专注于生成——将你脑海中的所有想法转化为视觉现实。在今年的 AI 生成领域（2025），图像编辑和视频生成非常流行。你一定在抖音或 YouTube 上看过 AI 生成的可爱动物视频、AI 创建的角色照片、AI 生成的肖像拍摄、切玻璃苹果的视频等等。在上完今天的图像和视频课程后，你也完全有能力创建同样的内容！

图片 API 的“接入链条”其实也不复杂。你可以先按 0 基础版本跑通一遍，再去追求更好的效果。

这一节同样先用一个例子“5 分钟跑通一次”，再讲清楚接入链条。

### 3.1 5 分钟接入生图 API：以 SiliconFlow Qwen-Image 为例

这一小节的目标只有一个：让你的原型“真的能生成一张图片”，快速跑通链路。

同样是 4 步（按顺序做）：

1. **拿到密钥（API Key）**：在 SiliconFlow 创建一个 API Key（相当于“通行证”）。
2. **找到官方示例**：在 SiliconFlow 文档里找到“生成图片”的示例（通常可以直接复制）。
3. **让 AI IDE 帮你接进原型**：把“密钥 + 官方示例 + 你原型里哪个按钮要生成图片”发给 AI IDE，让它把占位图/假图替换成真实生成。
4. **验证是否成功**：打开原型，输入一句图片描述（例如“白底电商主图、产品居中、柔光棚拍风格”），点击“生成主图”，能看到图片出来就算跑通。

同样，为了对齐到上一节的项目，你可以边打开原型边做这一小节：

> 上一节课项目：[1.2 动手做出原型（电商素材工作台）](/zh-cn/stage-1/1.2-building-prototype/)
>
> 你只需要找到里面的“生成主图/生成海报/生成配图”这类按钮，把它从“占位图/假图”升级成“真实生成”。

在素材工作台里，图片通常对应这样的入口：

- 输入“想要的画面描述”（例如白底、场景、风格、需要的文案）
- 点击“生成主图/生成海报”
- 页面出现一张图片（或一组图片）

你可以对 AI IDE 这样说：

```text
我有一个上一节做的电商素材工作台原型。

现在我需要把 [生成主图/生成海报/生成配图] 这个按钮接入真实的图片 API：
1) 点击按钮时，读取页面输入，整理成一句清楚的提示词；
2) 调用图片生成 API（例如 SiliconFlow Qwen-Image / Recraft / Seedream）；
3) 拿到返回的图片地址后，把图片显示在页面上；
4) 加上“生成中/失败提示”，并告诉我怎么验证。
```

<!-- TODO: 插入截图：SiliconFlow 创建 API Key 的页面 -->
<!-- TODO: 插入截图：SiliconFlow 图片生成的文档示例（可复制的那段） -->
<!-- TODO: 插入截图：AI IDE 对话（说明“我要把生图接入上一节的哪个按钮/页面”） -->
<!-- TODO: 插入截图：原型接入成功（点击按钮后出现生成图片） -->
<!-- TODO: 插入截图：素材工作台页面（图片提示词输入区 + “生成主图/生成海报”按钮） -->
<!-- TODO: 插入截图：接入成功后的页面（展示生成图片结果） -->

### 3.2 图片 API 的接入

把“图片 AI”接进原型，通常就 6 步：

1. **确定入口**：用户在哪里点一下，就应该开始“生成图片”？（例如“生成主图/生成海报/生成配图”）
2. **收集输入**：用户希望图片长什么样？（风格、场景、文字、颜色……）
3. **准备提示词**：把输入整理成一句清楚的话（例如“白底电商主图、产品居中、柔光棚拍风格”）
4. **发出请求**：用“密钥 + 官方示例”去请求图片服务
5. **拿到图片并展示**：通常会返回一个“图片地址”，你把它放到页面里就能看到图片
6. **加上加载/失败提示**：图片生成更慢，失败也更常见，提示要更清楚

<!-- TODO: 插入截图：原型中“生成图片/生成海报/生成主图”的入口（来自上一节的原型页面） -->

### 3.3 选择一个图片服务接入（示例）

下面给出三个常见选择。你只需要先选一个跑通即可：跑通之后，再尝试替换成你更喜欢的模型。

在今天的课程中，我们需要生成大量的图像和视频。为了方便起见，我们将使用统一连接的云服务提供商，并将提供相应的示例代码与调用密钥。你只需要按照以下步骤操作，就可以在你的原型中接入图像/视频能力。

![](images/image20.png)
![](images/image21.png)
![](images/image22.png)



## 3.4 将 SiliconFlow Qwen-Image API 集成到 AI IDE 中

在原型里，图片 API 最常见的落点是：**“生成主图 / 生成海报 / 生成配图”**。你需要做的事情很简单：把用户输入整理成一句话，请求图片 API，然后把返回的图片展示出来。

### 什么是 SiliconFlow

> [Silicon Flow (硅基流动)](https://cloud.siliconflow.com/me/models) 成立于 2023 年 8 月，是一家世界领先的 AI 能力提供商。它提供 SiliconCloud（具有自研推理加速的大模型云平台）和 BizyAir（用于 AI 图像生成的 ComfyUI 插件）等核心产品，为客户提供 AI 基础设施能力，拥有战略合作伙伴关系，并持有顶级行业认证。
>
> ![](images/image26.png)

### 什么是 Qwen-Image

> Qwen-Image 是一个强大的图像生成基础模型，能够进行复杂的文本渲染和精确的图像编辑。这是一个 20B MMDiT 图像基础模型，在复杂的文本渲染和精确的图像编辑方面取得了重大进展。实验表明，它在图像生成和编辑方面都具有很强的通用能力，在文本渲染方面表现尤为出色，尤其是中文。
>
> 从中文到英文，Qwen-Image 可以像 GPT-4o 或 Seedream 模型一样生成高质量的文本。
>
> ![](images/image27.png)
>
> ![](images/image28.png)
>
> ![](images/image29.png)
>
> ![](images/image30.png)

### 如何获取 SiliconFlow Qwen-Image API

入口：<https://cloud.siliconflow.com/me/models>

查看 SiliconFlow 的官网。左侧有一个“Playground”部分，你可以在不进行 API 调用的情况下试用不同的模型。在网页顶部有一个“Filters”按钮；点击它可以筛选右侧的模型列表。

如果你选择“Image”，你将只看到当前支持的所有文生图模型。在这种情况下，我们将使用 Qwen/Qwen-Image。

![](images/image31.png)

要调用 API，首先我们需要点击左侧设置中的“API Keys”，然后点击“Create API Key”按钮生成一个 API key。记得保存这个 API key。

![](images/image32.png)

要查看可用余额，我们需要打开左侧设置中的“Payments”。在这里，你可以看到 1 美元的赠金。但是，如果你想使用 FLUX 文生图模型，你需要先充值账户。

充值/余额：<https://cloud.siliconflow.com/me/account/ak>

![](images/image33.png)

一切设置好后，我们需要参考相应的图像生成 API 文档。你可以在官方文档页面找到任何标记为“API Reference”的部分。点击它，然后导航到图像生成的 API 端点部分并找到相关的请求示例。

文档入口：<https://docs.siliconflow.com/en/userguide/introduction>

![](images/image34.png)

```bash
curl --request POST \
  --url https://api.siliconflow.com/v1/images/generations \
  --header 'Authorization: Bearer <YOUR_API_KEY>' \
  --header 'Content-Type: application/json' \
  --data '{
  "model": "black-forest-labs/FLUX.1-Kontext-max",
  "prompt": "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
}'
```

记得将你打算使用的模型和 API key 填入相应的字段。之后，你可以在计算机的命令行中使用该命令运行直接请求测试。

```bash
curl --request POST \
  --url https://api.siliconflow.com/v1/images/generations \
  --header 'Authorization: Bearer <your_api_key>' \
  --header 'Content-Type: application/json' \
  --data '{
  "model": "Qwen/Qwen-Image",
  "prompt": "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
}'
```

![](images/image35.png)

你可以把「API Key + 官方请求示例 + 你的原型需求」发送给 AI IDE，并要求它帮你创建一个前端测试演示或直接改造当前项目。很快，你就能跑通 SiliconFlow 的基本 API 调用。

<!-- TODO: 插入截图：AI IDE 中说明“我要把图像 API 接到原型的哪个按钮/页面” -->

![](images/image36.png)

## 3.5 将 Recraft API 集成到 AI IDE 中

如果你的原型更偏“设计生产”（例如生成品牌风格插画、营销海报、矢量风格素材），Recraft 往往会更顺手。接入方式与上一节完全一致：**拿到 Key + 找到官方示例 + 让 AI IDE 把示例落到你的按钮/页面里**。

<!-- TODO: 插入截图：原型中 Recraft 的使用入口（例如“生成插画/生成海报”） -->

### 什么是 Recraft

> Recraft 是一款面向设计师、插画师和营销人员的 AI 工具——于 2022 年在美国成立，总部位于伦敦。它帮助生成/迭代视觉效果（图像、矢量艺术、3D 图形），具有高质量输出（任何文本大小/长度）、精确元素定位和品牌一致性设计等优势。受到 200 个国家/地区 300 多万用户（包括奥美、Netflix）的信任，并已创建了 3.5 亿多张图像，其团队旨在使其成为必备的设计师工具，确保创作者能够控制他们的 AI 辅助工作流程。
>
> ![](images/image37.png)
>
> ![](images/image38.png)
>
> ![](images/image39.png)

### 如何获取 Recraft API

首先，我们仍然需要找到 API 入口以获取 API Key：<https://www.recraft.ai/profile/api>

由于这里没有提供免费额度，我们需要自己充值 1,000 积分。这个网站支持支付宝和微信支付，所以很容易获得 1,000 积分（注意：不要充值超过必要的金额）。

![](images/image40.png)

之后，我们仍然遵循同样的方法：去官方文档找到相应的请求示例：

- <https://www.recraft.ai/docs/api-reference/getting-started>
- <https://www.recraft.ai/docs/api-reference/usage>
- <https://www.recraft.ai/docs/api-reference/guides>

在这里，我们可以直接复制官方文档中的请求示例，并粘贴到 AI IDE。

![](images/image41.png)

注意：在聊天窗口中，输入你的 API Key 和文档示例通常就足够了；AI IDE 会自动为你构建前端交互与请求代码。

<!-- TODO: 插入截图：AI IDE 粘贴 Recraft 示例并生成代码 -->

如果过程中出现错误，你可以直接将错误信息粘贴到聊天窗口，让 AI IDE 帮你自动解决。

![](images/image42.png)

## 3.6 将 Seedream API 集成到 AI IDE 中（针对中国用户）

如果你希望使用国内网络更稳定、且效果不错的图像生成服务，可以考虑 Seedream（火山引擎）。思路同样不变：把它当成一个“图片生成 API”，接到你的原型按钮上即可。

<!-- TODO: 插入截图：原型中 Seedream 的使用入口（例如“生成商品主图”） -->

### 什么是 Seedream 4.0

模型介绍：<https://seed.bytedance.com/en/seedream4_0>

![](images/image43.png)

> 也许你已经知道 Nano Banana（Google 开发），但你最好不要错过 Seedream。Seedream 4.0 是字节跳动打造的新一代图像创作模型。它将图像生成和图像编辑能力集成到一个统一的架构中。这使得它能够灵活处理复杂的多模态任务，如基于知识的生成、复杂推理和参考一致性。此外，它的推理速度比前代产品快得多，并且可以生成分辨率高达 4K 的令人惊叹的高清图像。
>
> ![](images/image44.png)
>
> ![](images/image45.png)
>
> ![](images/image46.png)

### 如何获取 Seedream API - 火山引擎 (Volcengine)（针对中国用户）

我们将逐步演示如何将 Seedream API 集成到你的项目中（通过 AI IDE 辅助完成）。

入口：<https://www.volcengine.com/experience/ark?launch=seedream>

访问页面后，点击登录。

![](images/image47.png)

登录后，找到页面右上角的充值选项。

![](images/image48.png)

进行充值需要实名认证。

![](images/image49.png)

认证成功后，你可以充值 1 元用于测试。

充值入口：<https://console.volcengine.com/finance/fund/recharge>

![](images/image50.png)

返回初始界面并点击 API 访问。

![](images/image51.png)

首先，创建一个 API key，然后点击选择选项。

![](images/image52.png)

这将带你进入第 2 步。在这里，你需要确认调用的服务是 Seedream 4.0，并复制提供的调用示例。

![](images/image53.png)

准备好 API Key 和调用示例后，你可以直接将它们粘贴到 AI IDE 中，让它生成前端交互演示或把能力接入现有原型。

<!-- TODO: 插入截图：AI IDE 粘贴 Seedream 示例并完成接入 -->

重要提示：这里的默认示例相对复杂。记得禁用“添加水印”选项和“流式响应”选项，以确保不生成水印且不会发生请求失败。

![](images/image54.png)

输入提示词后，你将收到生成的结果。享受它吧！

![](images/image55.png)

## 4. 📚 作业：给你自己的抖音电商工作台加上 AI 能力

<el-card shadow="hover" style="margin: 20px 0; border-radius: 12px;">
  <template #header>
    <div style="font-weight: bold; font-size: 16px;">🚀 挑战任务：让你的工作台“真的在用 AI”</div>
  </template>

  <p>
    请你基于上一节完成的「电商素材工作台」原型，完成一次“从原型到真实调用”的小闭环：
  </p>

  <ul>
    <li>
      <strong>必做 1：接入文字生成</strong>
      <ul>
        <li>把一个按钮接入真实的文字 API（例如“生成标题 / 生成卖点 / 一键改写”）</li>
        <li>点击后要能返回真实生成的文字，并展示在页面上（而不是写死的假数据）</li>
      </ul>
    </li>
    <li>
      <strong>必做 2：接入图片生成</strong>
      <ul>
        <li>把一个按钮接入真实的生图 API（例如“生成主图 / 生成海报 / 生成配图”）</li>
        <li>点击后要能返回真实生成的图片，并展示在页面上（而不是占位图/本地假图）</li>
      </ul>
    </li>
    <li>
      <strong>必做 3：补齐基础体验</strong>
      <ul>
        <li>至少包含“生成中”的提示</li>
        <li>失败时能给出提示（例如密钥无效、额度不足、网络失败）</li>
      </ul>
    </li>
    <li>
      <strong>自检清单</strong>
      <ul>
        <li>我能在页面上清楚地看到“生成按钮”和“生成结果”</li>
        <li>点击后不是写死的假数据，而是每次可能都不一样的真实结果</li>
        <li>报错时我能看懂原因，并知道下一步怎么处理（把报错复制给 AI IDE）</li>
      </ul>
    </li>
    <li>
      <strong>成果分享（可选）</strong>
      <ul>
        <li>截图你的页面（文字结果 + 图片结果）分享给同学/朋友</li>
      </ul>
    </li>
  </ul>
</el-card>

## 下一步

当你把“生成文字”和“生成图片”都接入成功后，你的工作台就已经具备了最核心的 AI 能力雏形：**点击按钮 → 发请求 → 拿结果 → 展示出来**。

接下来，你可以在这个内容生产工作台的基础上，继续扩展更多 AI 能力组合，例如：

- **文字生成文字**：一键生成多版标题/卖点、自动改写、批量生成不同风格文案
- **图片生成文字**：上传竞品/爆款截图，让 AI 自动总结卖点、提取关键信息、生成上新文案
- **文字生成图片**：根据商品描述自动生成配图草稿（主图/海报/详情页配图）

## 5. 附录：如何找到“当前更强”的 AI 模型

文字模型（也常被叫作“大语言模型”）的发展速度非常快，我们总是需要确保我们用的是表现更好的模型之一。通过以下两个网站，你可以很方便地看到“现在大家常用、评价也更好的模型”。

一般来说，这类网站可以理解为 **“模型竞技场”**：它会把两个模型的输出放在一起，你投票选你更喜欢的那个。票数高的模型，通常意味着更多人觉得它“更好用”。

此外，你偶尔可能会在这些大模型竞技场中看到神秘的匿名模型。通常，这些是来自 OpenAI 或 Google 等公司的内部测试模型。你可能有机会意外体验到最先进模型的能力！

### 5.1 LMArena

网站：<https://lmarena.ai/>

简介：LMArena 最初由加州大学伯克利分校大模型系统组织（LMSYS）作为一个学术副项目推出，现已发展成为一家公司。它是一个开源的众包 AI 基准测试平台。

它改变了传统的基于学科测试评估 AI 技术的方式，将评估权移交给社区用户。通过匿名和众包配对比较，它评估大规模模型。该平台支持超过 68 个模型，如 GPT-4o 和 Claude 3.5。

它使用 Elo 评分系统，可以更真实地反映用户对模型回答质量的评价。根据用户投票数据，它编制了一个排行榜，涵盖七个类别，包括文本/语言能力、Web 开发和视觉/图像理解。

截至 2025 年 4 月（撰写时），它已记录了超过 300 万次比较，并评估了 400 多个模型，是非常流行的众包对比平台。

![](images/image.png)

### 5.2 Artificial Analysis

网站：<https://artificialanalysis.ai/>

Artificial Analysis 是领先的独立 AI 基准测试和分析平台。它专注于对 AI 模型和 API 提供商进行独立分析。该网站提供详细的数据和图表，可以帮助开发者、用户、研究人员和其他用户做出明智的选择。

通过比较不同 AI 模型的质量、性能、价格和其他关键指标，它帮助用户找到最适合其需求的 AI 模型解决方案。

其功能包括模型比较、质量评估、价格分析、性能测试和上下文窗口分析。它还提供了详细的用户指南和常见问题解答，涵盖各种类型模型的评估，如大语言模型、文本到图像模型和语音到文本模型。此外，它还提供了一个专注于模型基准的免费 API 和一个具有更全面数据的商业 API。

![](images/index-2026-01-19-23-36-57.png)
